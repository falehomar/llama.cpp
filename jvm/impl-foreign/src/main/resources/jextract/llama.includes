

#### Extracted from: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h

--include-typedef llama_memory_t                                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-typedef llama_opt_param_filter                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-typedef llama_pos                                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-typedef llama_progress_callback                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-typedef llama_sampler_context_t                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-typedef llama_seq_id                                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-typedef llama_token                                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ATTENTION_TYPE_CAUSAL                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ATTENTION_TYPE_NON_CAUSAL                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ATTENTION_TYPE_UNSPECIFIED                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_DEFAULT_SEED                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FILE_MAGIC_GGLA                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FILE_MAGIC_GGSN                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FILE_MAGIC_GGSQ                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_ALL_F32                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_GUESSED                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_BF16                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_F16                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ1_M                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ1_S                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ2_M                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ2_S                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ2_XS                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ2_XXS                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ3_M                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ3_S                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ3_XS                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ3_XXS                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ4_NL                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_IQ4_XS                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q2_K                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q2_K_S                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q3_K_L                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q3_K_M                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q3_K_S                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q4_0                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q4_1                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q4_K_M                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q4_K_S                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q5_0                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q5_1                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q5_K_M                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q5_K_S                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q6_K                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_Q8_0                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_TQ1_0                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_FTYPE_MOSTLY_TQ2_0                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_KV_OVERRIDE_TYPE_BOOL                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_KV_OVERRIDE_TYPE_FLOAT                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_KV_OVERRIDE_TYPE_INT                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_KV_OVERRIDE_TYPE_STR                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_POOLING_TYPE_CLS                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_POOLING_TYPE_LAST                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_POOLING_TYPE_MEAN                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_POOLING_TYPE_NONE                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_POOLING_TYPE_RANK                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_POOLING_TYPE_UNSPECIFIED                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ROPE_SCALING_TYPE_LINEAR                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ROPE_SCALING_TYPE_LONGROPE                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ROPE_SCALING_TYPE_MAX_VALUE                                                          # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ROPE_SCALING_TYPE_NONE                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ROPE_SCALING_TYPE_UNSPECIFIED                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ROPE_SCALING_TYPE_YARN                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ROPE_TYPE_MROPE                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ROPE_TYPE_NEOX                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ROPE_TYPE_NONE                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ROPE_TYPE_NORM                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_ROPE_TYPE_VISION                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_SESSION_MAGIC                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_SESSION_VERSION                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_SPLIT_MODE_LAYER                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_SPLIT_MODE_NONE                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_SPLIT_MODE_ROW                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_STATE_SEQ_MAGIC                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_STATE_SEQ_VERSION                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_ATTR_BYTE                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_ATTR_CONTROL                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_ATTR_LSTRIP                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_ATTR_NORMAL                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_ATTR_NORMALIZED                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_ATTR_RSTRIP                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_ATTR_SINGLE_WORD                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_ATTR_UNDEFINED                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_ATTR_UNKNOWN                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_ATTR_UNUSED                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_ATTR_USER_DEFINED                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_NULL                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_TYPE_BYTE                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_TYPE_CONTROL                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_TYPE_NORMAL                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_TYPE_UNDEFINED                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_TYPE_UNKNOWN                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_TYPE_UNUSED                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_TOKEN_TYPE_USER_DEFINED                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_BAILINGMOE                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_BLOOM                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_CHAMELEON                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_CHATGLM3                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_CHATGLM4                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_CODESHELL                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_COMMAND_R                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_DBRX                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_DEEPSEEK3_LLM                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_DEEPSEEK_CODER                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_DEEPSEEK_LLM                                                          # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_DEFAULT                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_EXAONE                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_FALCON                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_GPT2                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_GPT3_FINNISH                                                          # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_GPT4O                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_JAIS                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_LLAMA3                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_LLAMA4                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_MINERVA                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_MPT                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_OLMO                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_PIXTRAL                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_PORO                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_QWEN2                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_REFACT                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_SEED_CODER                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_SMAUG                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_SMOLLM                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_STABLELM2                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_STARCODER                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_SUPERBPE                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_TEKKEN                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_TRILLION                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_PRE_TYPE_VIKING                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_TYPE_BPE                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_TYPE_NONE                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_TYPE_RWKV                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_TYPE_SPM                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_TYPE_UGM                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-constant LLAMA_VOCAB_TYPE_WPM                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_adapter_lora_free                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_adapter_lora_init                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_add_bos_token                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_add_eos_token                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_apply_adapter_cvec                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_attach_threadpool                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_backend_free                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_backend_init                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_batch_free                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_batch_get_one                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_batch_init                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_chat_apply_template                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_chat_builtin_templates                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_clear_adapter_lora                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_context_default_params                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_copy_state_data                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_decode                                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_detach_threadpool                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_detokenize                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_encode                                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_free                                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_free_model                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_get_embeddings                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_get_embeddings_ith                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_get_embeddings_seq                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_get_kv_self                                                                          # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_get_logits                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_get_logits_ith                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_get_memory                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_get_model                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_get_state_size                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_init_from_model                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_can_shift                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_clear                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_defrag                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_n_tokens                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_seq_add                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_seq_cp                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_seq_div                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_seq_keep                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_seq_pos_max                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_seq_pos_min                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_seq_rm                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_update                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_kv_self_used_cells                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_load_model_from_file                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_load_session_file                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_log_set                                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_max_devices                                                                          # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_max_parallel_sequences                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_memory_can_shift                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_memory_clear                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_memory_seq_add                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_memory_seq_cp                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_memory_seq_div                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_memory_seq_keep                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_memory_seq_pos_max                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_memory_seq_pos_min                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_memory_seq_rm                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_chat_template                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_cls_label                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_decoder_start_token                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_default_params                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_desc                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_free                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_get_vocab                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_has_decoder                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_has_encoder                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_is_recurrent                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_load_from_file                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_load_from_splits                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_meta_count                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_meta_key_by_index                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_meta_val_str                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_meta_val_str_by_index                                                          # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_n_cls_out                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_n_ctx_train                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_n_embd                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_n_head                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_n_head_kv                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_n_layer                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_n_params                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_n_swa                                                                          # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_quantize                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_quantize_default_params                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_rope_freq_scale_train                                                          # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_rope_type                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_save_to_file                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_model_size                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_n_batch                                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_n_ctx                                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_n_ctx_train                                                                          # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_n_embd                                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_n_head                                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_n_layer                                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_n_seq_max                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_n_threads                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_n_threads_batch                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_n_ubatch                                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_n_vocab                                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_new_context_with_model                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_numa_init                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_opt_epoch                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_opt_init                                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_opt_param_filter_all                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_perf_context                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_perf_context_print                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_perf_context_reset                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_perf_sampler                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_perf_sampler_print                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_perf_sampler_reset                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_pooling_type                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_print_system_info                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_rm_adapter_lora                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_accept                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_apply                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_chain_add                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_chain_default_params                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_chain_get                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_chain_init                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_chain_n                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_chain_remove                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_clone                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_free                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_get_seed                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_dist                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_dry                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_grammar                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_grammar_lazy                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_grammar_lazy_patterns                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_greedy                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_infill                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_logit_bias                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_min_p                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_mirostat                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_mirostat_v2                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_penalties                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_softmax                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_temp                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_temp_ext                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_top_k                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_top_n_sigma                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_top_p                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_typical                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_init_xtc                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_name                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_reset                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_sampler_sample                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_save_session_file                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_set_abort_callback                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_set_adapter_lora                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_set_causal_attn                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_set_embeddings                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_set_n_threads                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_set_state_data                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_set_warmup                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_split_path                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_split_prefix                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_state_get_data                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_state_get_size                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_state_load_file                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_state_save_file                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_state_seq_get_data                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_state_seq_get_size                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_state_seq_load_file                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_state_seq_save_file                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_state_seq_set_data                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_state_set_data                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_supports_gpu_offload                                                                 # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_supports_mlock                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_supports_mmap                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_supports_rpc                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_synchronize                                                                          # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_time_us                                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_bos                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_cls                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_eos                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_eot                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_fim_mid                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_fim_pad                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_fim_pre                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_fim_rep                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_fim_sep                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_fim_suf                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_get_attr                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_get_score                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_get_text                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_is_control                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_is_eog                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_nl                                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_pad                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_sep                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_token_to_piece                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_tokenize                                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_bos                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_cls                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_eos                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_eot                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_fim_mid                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_fim_pad                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_fim_pre                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_fim_rep                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_fim_sep                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_fim_suf                                                                        # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_get_add_bos                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_get_add_eos                                                                    # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_get_attr                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_get_score                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_get_text                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_is_control                                                                     # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_is_eog                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_n_tokens                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_nl                                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_pad                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_sep                                                                            # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-function llama_vocab_type                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_adapter_lora                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_batch                                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_chat_message                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_context                                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_context_params                                                                         # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_kv_cache                                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_logit_bias                                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_memory_i                                                                               # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_model                                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_model_kv_override                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_model_params                                                                           # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_model_quantize_params                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_model_tensor_buft_override                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_opt_params                                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_perf_context_data                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_perf_sampler_data                                                                      # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_sampler                                                                                # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_sampler_chain_params                                                                   # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_sampler_i                                                                              # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_token_data                                                                             # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_token_data_array                                                                       # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
--include-struct llama_vocab                                                                                  # header: /Users/e168693/TeamCompose/submodules/llama.cpp/include/llama.h
