rootProject.name = 'llama-cpp-jvm-tools'

// Include all tool projects
include 'tokenization'
include 'model-loader'
include 'context-manager'
include 'batch-processor'
include 'sampling'
include 'embeddings'
include 'kv-cache'
include 'server'
include 'benchmarking'
include 'tts'

// Configure project paths
project(':tokenization').projectDir = file('io.github.llama.tools.tokenization')
project(':model-loader').projectDir = file('io.github.llama.tools.model-loader')
project(':context-manager').projectDir = file('io.github.llama.tools.context-manager')
project(':batch-processor').projectDir = file('io.github.llama.tools.batch-processor')
project(':sampling').projectDir = file('io.github.llama.tools.sampling')
project(':embeddings').projectDir = file('io.github.llama.tools.embeddings')
project(':kv-cache').projectDir = file('io.github.llama.tools.kv-cache')
project(':server').projectDir = file('io.github.llama.tools.server')
project(':benchmarking').projectDir = file('io.github.llama.tools.benchmarking')
project(':tts').projectDir = file('io.github.llama.tools.tts')
